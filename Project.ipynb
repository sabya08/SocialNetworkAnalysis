{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#PROJECT : Analysis of Users Preferences between Android and iOS \n",
    "Here we'll implement a sentiment analysis analysisng preferences of users between Android and iOS.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tweepy.streaming import StreamListener\n",
    "from tweepy import OAuthHandler\n",
    "from tweepy import Stream\n",
    "import json, time, sys, io, pickle\n",
    "import re\n",
    "import tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "access_token = \"97387398-09aWi5l77s95Vy7Jag58WvQ1soy9TzoGCA0vruWH5\"\n",
    "access_token_secret = \"ZzBHbF3LjXg7Wl40VIa6nJomv1TdwQW9Am1oQRzIW0RLN\"\n",
    "consumer_key = \"Ii9orQvVcYDTzbk5feDFIuz1n\"\n",
    "consumer_secret = \"MXTqped02xYhyuer6IpO2Rt2377MRGsTHhJQnMZ9aOagGrTLnD\"\n",
    "\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class TweetsListener(tweepy.StreamListener):\n",
    "\n",
    "    def __init__(self, filename=None, api=None):\n",
    "        super(TweetsListener, self).__init__()\n",
    "        self.num_tweets = 0\n",
    "        self.filename = filename\n",
    "    \n",
    "    def on_status(self, status):\n",
    "        record = {'Text': status.text.encode('utf-8').strip(), 'Created At': str(status.created_at)}\n",
    "        if self.num_tweets < 1000:\n",
    "            try:\n",
    "                with open(self.filename, 'a') as f:\n",
    "                    pickle.dump(record,f)\n",
    "                    self.num_tweets += 1\n",
    "                return True\n",
    "            except BaseException as e:\n",
    "                print(\"Error on_status: %s\" % str(e))\n",
    "        else:\n",
    "            return False\n",
    "        \n",
    "    def on_error(self, status):\n",
    "        print 'Error on status', status\n",
    "\n",
    "    def on_limit(self, status):\n",
    "        print 'Limit threshold exceeded', status\n",
    "\n",
    "    def on_timeout(self, status):\n",
    "        print 'Stream disconnected; continuing...'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# stream = Stream(auth, TweetsListener(filename = 'data_android.json'))\n",
    "# stream.filter(track=['android','androidvsios','iosvsandroid'],languages=['en'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# stream = Stream(auth, TweetsListener(filename = 'data_ios.json'))\n",
    "# stream.filter(track=['iphone','ios','androidvsios','iosvsandroid'],languages=['en'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def readTweets(filename):\n",
    "    list = []\n",
    "    with open(filename, 'r') as f:\n",
    "        for x in range(0,1000):\n",
    "            list.append(pickle.load(f)['Text'])\n",
    "    return list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def tokenize_with_not(text):\n",
    "    \"\"\"Does the same thing as tokenize_with_punct, with the following difference:\n",
    "    whenever the term 'not' appears, change the two subsequent tokens to have the prefix\n",
    "    'not_' prior to the token. See the example below. You may call \n",
    "    tokenize_with_punct as a subroutine.\n",
    "    Params:\n",
    "        text....a string\n",
    "    Returns:\n",
    "        a list of tokens\n",
    "    \"\"\"\n",
    "    ###TODO\n",
    "    text = re.sub(r'[\\x85]',\"\",text)\n",
    "    tokens = tokenize_with_punct(text)\n",
    "    i=0\n",
    "    while i< len(tokens):\n",
    "        if tokens[i] == \"not\":\n",
    "            if(i+1 < len(tokens)):\n",
    "                tokens[i+1] = 'not_' + tokens[i+1]\n",
    "            if(i+2 < len(tokens)):\n",
    "                tokens[i+2] = 'not_' + tokens[i+2]\n",
    "            i = i+3\n",
    "        else:\n",
    "            i = i+1\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def writeListToTextFile(list,filename):\n",
    "    f = open(filename, \"w\")\n",
    "    for item in list:\n",
    "      print>>f, item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "list_android = readTweets('data_android.json')\n",
    "writeListToTextFile(list_android,'data_android.txt')\n",
    "list_ios = readTweets('data_ios.json')\n",
    "writeListToTextFile(list_ios,'data_ios.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def processTweet(tweet):\n",
    "    # process the tweets\n",
    "\n",
    "    #Convert to lower case\n",
    "    tweet = tweet.lower()\n",
    "    #Convert www.* or https?://* to URL\n",
    "    tweet = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))','URL',tweet)\n",
    "    #Convert @username to AT_USER\n",
    "    tweet = re.sub('@[^\\s]+','AT_USER',tweet)\n",
    "    #Remove additional white spaces\n",
    "    tweet = re.sub('[\\s]+', ' ', tweet)\n",
    "    #Replace #word with word\n",
    "    tweet = re.sub(r'#([^\\s]+)', r'\\1', tweet)\n",
    "    #trim\n",
    "    tweet = tweet.strip('\\'\"')\n",
    "    return tweet\n",
    "#end\n",
    "\n",
    "#Read the tweets one by one and process it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preProcessTweets(filename):\n",
    "    fp = open(filename, 'r')\n",
    "    fpn = open('process'+filename,'w')\n",
    "    line = fp.readline()\n",
    "    while line:\n",
    "        processedTweet = processTweet(line)\n",
    "        print>>fpn, processedTweet\n",
    "        line = fp.readline()\n",
    "    #end loop\n",
    "    fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preProcessTweets('data_android.txt')\n",
    "preProcessTweets('data_ios.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
